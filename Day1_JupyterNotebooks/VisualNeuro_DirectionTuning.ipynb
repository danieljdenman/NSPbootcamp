{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note: \n",
    "please create a fresh Anaconda env:<br>\n",
    "`conda create -n allensdk pip numpy=1.18.1 pandas=0.25.1 jupyterlab`<br>\n",
    "`conda activate allensdk`<br>\n",
    "`pip install allensdk`\n",
    "\n",
    "and relaunch this Jupyter Lab server:<br>\n",
    "`jupyter lab`<br>\n",
    "before running this notebook\n",
    "\n",
    "## or\n",
    "run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting argschema\n",
      "  Using cached argschema-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /Users/danieljdenman/opt/anaconda3/envs/NSPbootcamp/lib/python3.9/site-packages (from argschema) (6.0)\n",
      "Requirement already satisfied: marshmallow<4.0,>=3.0.0 in /Users/danieljdenman/opt/anaconda3/envs/NSPbootcamp/lib/python3.9/site-packages (from argschema) (3.17.1)\n",
      "Requirement already satisfied: numpy in /Users/danieljdenman/opt/anaconda3/envs/NSPbootcamp/lib/python3.9/site-packages (from argschema) (1.21.5)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/danieljdenman/opt/anaconda3/envs/NSPbootcamp/lib/python3.9/site-packages (from marshmallow<4.0,>=3.0.0->argschema) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/danieljdenman/opt/anaconda3/envs/NSPbootcamp/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0,>=3.0.0->argschema) (3.0.4)\n",
      "Installing collected packages: argschema\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allensdk 2.13.6 requires boto3==1.17.21, which is not installed.\n",
      "allensdk 2.13.6 requires future<1.0.0,>=0.14.3, which is not installed.\n",
      "allensdk 2.13.6 requires glymur==0.8.19, which is not installed.\n",
      "allensdk 2.13.6 requires ndx-events<=0.2.0, which is not installed.\n",
      "allensdk 2.13.6 requires psycopg2-binary<3.0.0,>=2.7, which is not installed.\n",
      "allensdk 2.13.6 requires pynrrd<1.0.0,>=0.2.1, which is not installed.\n",
      "allensdk 2.13.6 requires scikit-build<1.0.0, which is not installed.\n",
      "allensdk 2.13.6 requires semver, which is not installed.\n",
      "allensdk 2.13.6 requires sqlalchemy, which is not installed.\n",
      "allensdk 2.13.6 requires aiohttp==3.7.4, but you have aiohttp 3.8.1 which is incompatible.\n",
      "allensdk 2.13.6 requires cachetools<5.0.0,>=4.2.1, but you have cachetools 5.2.0 which is incompatible.\n",
      "allensdk 2.13.6 requires matplotlib<3.4.3,>=1.4.3, but you have matplotlib 3.5.2 which is incompatible.\n",
      "allensdk 2.13.6 requires scikit-image<0.17.0,>=0.14.0, but you have scikit-image 0.19.2 which is incompatible.\n",
      "allensdk 2.13.6 requires statsmodels<=0.13.0, but you have statsmodels 0.13.2 which is incompatible.\n",
      "allensdk 2.13.6 requires tables<3.7.0,>=3.6.0, but you have tables 3.7.0 which is incompatible.\n",
      "allensdk 2.13.6 requires xarray<0.16.0, but you have xarray 2022.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed argschema-3.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install allensdk --no-dependencies\n",
    "!pip install xarray pynwb requests_toolbelt SimpleITK simplejson tqdm marshmallow argschema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Direction Tuning with Python in a Jupyter notebook\n",
    "We're going to use data from [Siegle, Jia et al., bioRxiv 2019](https://www.biorxiv.org/content/10.1101/805010v1) for this notebook. This is Neuropixels data collected in several visual areas in the awake mouse brain, while the mouse is viewing visual stimuli. We'll get the data using the [Allen Software Development Kit](https://allensdk.readthedocs.io/en/latest/), which Python to programmatically access [this data](https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html). There are other example Jupyter notebooks, as well as more documentation for the SDK and Neuropixels datasets at the Allen SDK Neuropixels [link](https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html).\n",
    "<br>The goal will be to get some spikes times, some stimulus times, and plot direction tuning curves like this one on the right:. \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hubel and Wiesel, 1968](../res/HW68_DS.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some of the code is pre-written, and you will simply execute it. In other cases, you will be prompted to write some code lines to advance towards this goal. **There are going to be 8 such prompts,** plus some bonus challenges if you want to keep going.\n",
    "\n",
    "## Imports of packages we will need for this notebook. \n",
    "#### All are standard and those that we have talked about, plus the AllenSDK for gettting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys,glob\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache, EcephysSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will get the Neuropixels data from the Allen Institute servers. \n",
    "The details of this are not critical, and can be ignored for now in order to get the rest of this notebook. There are some useful examples of working with a pandas DataFrame, and a desription of class objects for some slightly more advanced Pythoning. You can skip to the big\n",
    "# ==========================================================\n",
    "\n",
    "below if you'd like, but you have to run these cells first. So, some Jupyter practice: press ```Shift + Enter``` to run a cell and advance to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '~/' \n",
    "manifest_path = os.path.join(data_directory, \"manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "sessions = cache.get_session_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important result of this  is that we will end up with a pandas DataFrame with sessions (i.e., recording sessions) in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sessions: 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_at</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>session_type</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>sex</th>\n",
       "      <th>full_genotype</th>\n",
       "      <th>unit_count</th>\n",
       "      <th>channel_count</th>\n",
       "      <th>probe_count</th>\n",
       "      <th>ecephys_structure_acronyms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715093703</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>699733581</td>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>884</td>\n",
       "      <td>2219</td>\n",
       "      <td>6</td>\n",
       "      <td>[CA1, VISrl, nan, PO, LP, LGd, CA3, DG, VISl, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719161530</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>703279284</td>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>755</td>\n",
       "      <td>2214</td>\n",
       "      <td>6</td>\n",
       "      <td>[TH, Eth, APN, POL, LP, DG, CA1, VISpm, nan, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721123822</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>707296982</td>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt</td>\n",
       "      <td>444</td>\n",
       "      <td>2229</td>\n",
       "      <td>6</td>\n",
       "      <td>[MB, SCig, PPT, NOT, DG, CA1, VISam, nan, LP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732592105</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>717038288</td>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>M</td>\n",
       "      <td>wt/wt</td>\n",
       "      <td>824</td>\n",
       "      <td>1847</td>\n",
       "      <td>5</td>\n",
       "      <td>[grey, VISpm, nan, VISp, VISl, VISal, VISrl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737581020</th>\n",
       "      <td>2019-10-03T00:00:00Z</td>\n",
       "      <td>718643567</td>\n",
       "      <td>brain_observatory_1.1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>M</td>\n",
       "      <td>wt/wt</td>\n",
       "      <td>568</td>\n",
       "      <td>2218</td>\n",
       "      <td>6</td>\n",
       "      <td>[grey, VISmma, nan, VISpm, VISp, VISl, VISrl]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   published_at  specimen_id           session_type  \\\n",
       "id                                                                    \n",
       "715093703  2019-10-03T00:00:00Z    699733581  brain_observatory_1.1   \n",
       "719161530  2019-10-03T00:00:00Z    703279284  brain_observatory_1.1   \n",
       "721123822  2019-10-03T00:00:00Z    707296982  brain_observatory_1.1   \n",
       "732592105  2019-10-03T00:00:00Z    717038288  brain_observatory_1.1   \n",
       "737581020  2019-10-03T00:00:00Z    718643567  brain_observatory_1.1   \n",
       "\n",
       "           age_in_days sex                                    full_genotype  \\\n",
       "id                                                                            \n",
       "715093703        118.0   M    Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt   \n",
       "719161530        122.0   M    Sst-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt   \n",
       "721123822        125.0   M  Pvalb-IRES-Cre/wt;Ai32(RCL-ChR2(H134R)_EYFP)/wt   \n",
       "732592105        100.0   M                                            wt/wt   \n",
       "737581020        108.0   M                                            wt/wt   \n",
       "\n",
       "           unit_count  channel_count  probe_count  \\\n",
       "id                                                  \n",
       "715093703         884           2219            6   \n",
       "719161530         755           2214            6   \n",
       "721123822         444           2229            6   \n",
       "732592105         824           1847            5   \n",
       "737581020         568           2218            6   \n",
       "\n",
       "                                  ecephys_structure_acronyms  \n",
       "id                                                            \n",
       "715093703  [CA1, VISrl, nan, PO, LP, LGd, CA3, DG, VISl, ...  \n",
       "719161530  [TH, Eth, APN, POL, LP, DG, CA1, VISpm, nan, N...  \n",
       "721123822  [MB, SCig, PPT, NOT, DG, CA1, VISam, nan, LP, ...  \n",
       "732592105       [grey, VISpm, nan, VISp, VISl, VISal, VISrl]  \n",
       "737581020      [grey, VISmma, nan, VISpm, VISp, VISl, VISrl]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total number of sessions: ' + str(len(sessions)))\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a pandas dataframe, we can easilty search the values (for example, for genotype) and filter it (for example, for wild type C57s only, male, with a probe in primary visual cortex (VISp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, what kind of genoypes are there? we can query the pandas DataFrame ```sessions``` with ```.unique()``` to find all of the genotpyes in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.full_genotype.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sessions = sessions[(sessions.sex == 'M') & \\\n",
    "                             (sessions.full_genotype == 'wt/wt') & \\\n",
    "                             (sessions.session_type == 'brain_observatory_1.1') & \\\n",
    "                             (['VISp' in acronyms for acronyms in \n",
    "                               sessions.ecephys_structure_acronyms])]\n",
    "\n",
    "filtered_sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for our purposes, you should choose a session that has ```session_type` =='brain_observatory_1.1'``` and ```['VISp' in acronyms for acronyms in sessions.ecephys_structure_acronyms]```. but beyond that, you could chooose any session. i'll choose the last session in my ```filtered_sessions``` DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note: To save time [and because the AllenSDK is flaky with Neuropixels data because of the Allen servers], i've downloaded this session already and stored it in the Google cloud such that you can access it directly. I left the AllenSDK call in this cell, but commented it out, so you can see how straightforward it **might** have been to get this data. You can also see this in the the TimeSeries_PatchClamp.ipynb, another of our Day1 options.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allensdk.brain_observatory.ecephys.ecephys_session import EcephysSession\n",
    "# #AllenSDK\n",
    "# session = cache.get_session_data(filtered_sessions.index.values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://storage.googleapis.com/nsp_bootcamp/ecephys_session_799864342.nwb\", stream = True)\n",
    "with open(os.path.join('..','data','ecephys_session_799864342.nwb'), \"wb\") as p:\n",
    "    for chunk in r.iter_content(chunk_size = 1024):\n",
    "        if chunk:\n",
    "            p.write(chunk)\n",
    "session = EcephysSession.from_nwb_path(os.path.join('..','data','ecephys_session_799864342.nwb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the data (recorded neural data, stimulus information) for one recording session. let's take a pause and assess what we have. what is the data type of ```session```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a data object that is not a basic type! what is an \"EcephysSession\"? it's a class object defined by the AllenSDK. classes have functions (methods) of their own, and attributes. both are accessed with by putting a ```.``` after the class object. here's funky line that will tell us what all of the attributes of ```session``` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([attr_or_method for attr_or_method in dir(session) if attr_or_method[0] != '_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_units = session.units[session.units.ecephys_structure_acronym == 'VISp']\n",
    "v1_spike_times = [session.spike_times[cell] for cell in session.units.index[session.units.ecephys_structure_acronym == 'VISp']]\n",
    "v1_units['spike_times']=v1_spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: this one might take a few seconds to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "## Now we've got data, let's get to work. Our initial goal is to determine the preferred direction of a neuron in V1. Something like the right side of this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hubel and Wiesel, 1968](../res/HW68_DS.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a plot like this, we need know \n",
    "1. the times of the spikes from each neuron, and \n",
    "2. the times of the stimuli of the various directions.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start with spike times. above, we got the \"units\" (a.k.a. \"neurons\") from primary visual cortex recorded and isolated in this session. Their information is in ```v1_units```. \n",
    "<br>**First question of this exercise:<br>Q1. What type of data is ```v1_units```? write some code that will give the answer in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. How many neurons were recorded in V1 in this recording? write some code that will give the answer in the cell below:**\n",
    "_note: there is not one way to do this; there are several. any is fine!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, so we have ___ neurons in V1 in this recording. Let's choose one and look at it's spike times. \n",
    "<--**if you want, put your answer to how many neurons we have in V1 here**<br>\n",
    "i'll choose (semi-randomly, unit 951095552):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_units.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_neuron_spike_times = v1_units[v1_units.index==v1_units.index[8]].spike_times.values[0]\n",
    "print(chosen_neuron_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, now we have ```chosen_neuron_spike_times```, in seconds. how do we get the oriented stimulus times? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get all of the stimulus information from the ```session``` object. The details of this ```session``` object are beyond the scope here, but the stimlus information is all in a pandas DataFrame in ```session``` so we will get it (and call in ```stimuli```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = session.stimulus_presentations\n",
    "print(type(stimuli))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: this cell may take a few seconds, be patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what kind of stimuli were there? we can use the nice ```.unique()``` method of pandas Series (column) or DataFrame (table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli.stimulus_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want  ```'drifting_gratings'```, which is the type of stimulus that has oriented stimuli for making an direction tuning curve. We filter all of the stimuli to get onlu the grating stimuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grating_stimuli = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'drifting_gratings']\n",
    "grating_stimuli = grating_stimuli[grating_stimuli.orientation != 'null']\n",
    "print(grating_stimuli.orientation.unique()) # ignore the fact that this is called \"orientation\" and not \"direction\". can't win them all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note, we have grating stimuli with various directions, separated by 45ยบ. great for making an direction tuning curve! what else do we know about these grating stimuli? we'll use ```.head()``` to show us just the first five entries in ```grating_stimuli```, that way we can read all of the columns and get a flavor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grating_stimuli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice the column ```start_time```. this is the start of each grating presentation, in seconds. \n",
    "<br> so, to get the stimulus times of each grating with an direction of 0ยบ, we filter the ```grating_stimuli``` DataFrame again, and get the ```.start_time``` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_0_times = grating_stimuli.start_time[grating_stimuli.orientation==0.0].values\n",
    "print(len(direction_0_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grating of direction 0ยบ was shown 75 times.<br>\n",
    "**Q3: How long (in duration) was each of these 75 presentations? make a variable called ```duration``` and assign it your answer (in seconds). note that ```duration``` should be a ```float```** <br>_hint: look at the other column names in ```grating_stimuli```_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now answer the question: for direction X how many spikes did your chosen v1 cell fire during the stimulus presentation period (start time + duration)? We will do so by counting the spike times of our chose v1 cell that occur between ```start_time``` and ```start_time``` + ```duration```. first, i'll write this out in the most explicit way possible, with ```for``` loops and ```if``` statements. <br>For demonstration purposes, let's also time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dir0_counts = []\n",
    "for start_time in direction_0_times:\n",
    "    count = 0\n",
    "    for spike_time in chosen_neuron_spike_times:\n",
    "        if spike_time > start_time:\n",
    "            if spike_time < start_time + duration:\n",
    "                count = count + 1\n",
    "    dir0_counts.extend([count])\n",
    "print('that took: '+str(time.time()-start)+' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above code works, but it is pretty slow and inefficent (in terms of lines of code). using ```numpy```'s ```np.where``` function and a python concept called list comprehension, we can do this in one line, and lightning fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dir0_counts2 = [len(np.where((chosen_neuron_spike_times >= start_time) & (chosen_neuron_spike_times <=start_time+duration))[0]) for start_time in direction_0_times]\n",
    "print('that took: '+str(time.time()-start)+' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note, reassuringly, that we got the same answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0_counts == dir0_counts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start making our direction tuning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = np.array([0]) # in degrees\n",
    "mean_spike_count = np.array([np.mean(dir0_counts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(os.path.join('..','data','ecephys_session_799864342.nwb'),\"wb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welp, the plot didn't work.<br>\n",
    "**Q4: why not? make the above plot work, without changing the code in the cell. add a cell above it, and then rerun the cell with ```plt.plot(direction,mean_spike_count)``` (or...if it did work...what had you done that made it work?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a plot! Let's finish making our direction tuning curve. We need to iterate over all of the presented directions. <br>\n",
    "**Q5: What are all of the presented stimulus directions in this session? iterate over all of them, printing them in each iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb0f08f5ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6: iterate over the stimulus directions again, but this time instead of printing them, count the number of spikes within the duration.** _hint: go back and look at how we did this for dir0_counts2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7: plot the mean spike count as a function of direction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(??????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8: add error bars (standard deviation) to the plot from Q7. use plt.errorbar(), and note that you can measure the standard deviation of a list or array of spike counts with np.std()**<br> this may or may not take a few lines or cells to recompute the standard deviation. feel free to work below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(?????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus!<br>**Convert the spike counts to firing rate (spikes / sec)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus!<br>**What is the cells's preferred orientation (the orientation with the highest mean evoked spike count?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
